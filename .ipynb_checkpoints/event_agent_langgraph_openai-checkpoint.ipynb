{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "018606d6",
   "metadata": {},
   "source": [
    "\n",
    "# Event Agent with LangGraph + OpenAI\n",
    "\n",
    "This notebook wires your graph to a **real OpenAI LLM** for the signal evaluation step.\n",
    "It includes:\n",
    "- Auto‑install for required packages (`openai`, `python-dotenv`).\n",
    "- `.env` loading for `OPENAI_API_KEY` (no hardcoding keys).\n",
    "- A `signal_evaluation_node` that calls OpenAI and expects **JSON output**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff338292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-install packages in this kernel if missing\n",
    "import sys, importlib, subprocess\n",
    "def ensure(pkg, import_name=None):\n",
    "    mod = import_name or pkg.replace(\"-\", \"_\")\n",
    "    try:\n",
    "        importlib.import_module(mod)\n",
    "        print(f\"{pkg} already installed.\")\n",
    "    except Exception:\n",
    "        print(f\"Installing {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", pkg])\n",
    "        importlib.invalidate_caches()\n",
    "        importlib.import_module(mod)\n",
    "        print(f\"{pkg} installed.\")\n",
    "        \n",
    "ensure(\"langgraph\")\n",
    "ensure(\"openai\")\n",
    "ensure(\"python-dotenv\", \"dotenv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c55b2e",
   "metadata": {},
   "source": [
    "## Setup OpenAI client (reads `OPENAI_API_KEY` from your environment or `.env`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env from current dir or parents if present\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"⚠️ OPENAI_API_KEY not found. Set it in your environment or create a .env with:\")\n",
    "    print(\"OPENAI_API_KEY=sk-...\")\n",
    "else:\n",
    "    print(\"✅ OPENAI_API_KEY detected\")\n",
    "\n",
    "# Choose a model; override by setting OPENAI_MODEL in env\n",
    "MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "print(\"Using model:\", MODEL)\n",
    "\n",
    "# Build client\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f21e229",
   "metadata": {},
   "source": [
    "## Define the Graph State and Nodes (LLM-powered signal evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import random\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "    \n",
    "    Attributes:\n",
    "        event_data (str): The raw user event data (e.g., a new signup).\n",
    "        signals (dict): A dictionary of signals classified from the event.\n",
    "        action (str): The final action decided upon (e.g., 'remove_account').\n",
    "        log_entry (str): A summary of the event for logging and reporting.\n",
    "    \"\"\"\n",
    "    event_data: str\n",
    "    signals: dict\n",
    "    action: str\n",
    "    log_entry: str\n",
    "\n",
    "def user_event_node(state: GraphState) -> GraphState:\n",
    "    print(\"--- 1. User Event Node: Received new event ---\")\n",
    "    return {\"event_data\": state.get(\"event_data\", \"\"), \"signals\": {}, \"action\": \"\", \"log_entry\": \"\"}\n",
    "\n",
    "def signal_evaluation_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"Calls OpenAI to classify the event and return JSON signals.\n",
    "    \n",
    "    Expected JSON:\n",
    "    {\n",
    "      \"suspicious_signup\": true/false,\n",
    "      \"normal_signup\": true/false\n",
    "    }\n",
    "    Exactly one should be true.\n",
    "    \"\"\"\n",
    "    print(\"--- 2. Signal Evaluation Node: LLM classifying event ---\")\n",
    "    event = state.get(\"event_data\", \"\")\n",
    "    prompt = f\"\"\"You are a JSON-only classifier for account signup events.\n",
    "Return a JSON object with exactly two boolean keys:\n",
    "- suspicious_signup\n",
    "- normal_signup\n",
    "\n",
    "Set exactly ONE of them to true and the other to false.\n",
    "\n",
    "Event: {event}\n",
    "\"\"\"\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a strict JSON API. Return ONLY valid JSON.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            temperature=0\n",
    "        )\n",
    "        content = resp.choices[0].message.content\n",
    "        data = json.loads(content)\n",
    "        signals = {\n",
    "            \"suspicious_signup\": bool(data.get(\"suspicious_signup\", False)),\n",
    "            \"normal_signup\": bool(data.get(\"normal_signup\", False)),\n",
    "        }\n",
    "        # Sanity guard: ensure exactly one is True\n",
    "        if signals[\"suspicious_signup\"] == signals[\"normal_signup\"]:\n",
    "            # fall back to heuristic if ambiguous\n",
    "            heur = \"suspicious\" in event.lower() or (\"director\" in event.lower() and \"22\" in event.lower())\n",
    "            signals = {\"suspicious_signup\": heur, \"normal_signup\": not heur}\n",
    "    except Exception as e:\n",
    "        print(\"LLM error, falling back to heuristic:\", e)\n",
    "        heur = \"suspicious\" in event.lower() or (\"director\" in event.lower() and \"22\" in event.lower())\n",
    "        signals = {\"suspicious_signup\": heur, \"normal_signup\": not heur}\n",
    "    return {\"signals\": signals}\n",
    "\n",
    "def action_decision_node(state: GraphState) -> GraphState:\n",
    "    print(\"--- 3. Action Decision Node: Deciding on account action ---\")\n",
    "    signals = state.get(\"signals\", {})\n",
    "    action = \"no_action\"\n",
    "    if signals.get(\"suspicious_signup\"):\n",
    "        action = \"remove_account\" if random.random() > 0.5 else \"hold_account\"\n",
    "    else:\n",
    "        action = \"no_action\"\n",
    "    return {\"action\": action}\n",
    "\n",
    "def logging_node(state: GraphState) -> GraphState:\n",
    "    print(\"--- 4. Logging Node: Logging final event outcome ---\")\n",
    "    log_summary = {\n",
    "        \"event\": state.get(\"event_data\", \"N/A\"),\n",
    "        \"signals_detected\": state.get(\"signals\", {}),\n",
    "        \"final_action\": state.get(\"action\", \"N/A\")\n",
    "    }\n",
    "    log_entry = json.dumps(log_summary, indent=2)\n",
    "    print(\"\\n--- Final Log Entry ---\\n\" + log_entry)\n",
    "    return {\"log_entry\": log_entry}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdd9d11",
   "metadata": {},
   "source": [
    "## Assemble and Compile the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1184cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"user_event_node\", user_event_node)\n",
    "workflow.add_node(\"signal_evaluation_node\", signal_evaluation_node)\n",
    "workflow.add_node(\"action_decision_node\", action_decision_node)\n",
    "workflow.add_node(\"logging_node\", logging_node)\n",
    "\n",
    "workflow.add_edge(START, \"user_event_node\")\n",
    "workflow.add_edge(\"user_event_node\", \"signal_evaluation_node\")\n",
    "workflow.add_edge(\"signal_evaluation_node\", \"action_decision_node\")\n",
    "workflow.add_edge(\"action_decision_node\", \"logging_node\")\n",
    "workflow.add_edge(\"logging_node\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "print(\"Graph compiled with OpenAI-backed classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf94917",
   "metadata": {},
   "source": [
    "## Test the Graph with Different Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dfb201",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==========================================================\")\n",
    "print(\"TESTING SCENARIO 1: SUSPICIOUS SIGNUP\")\n",
    "print(\"==========================================================\")\n",
    "suspicious_event = \"NEW SIGNUP: I am a 22 year old Director making $200,000 per year.\"\n",
    "final_state_1 = app.invoke({\"event_data\": suspicious_event})\n",
    "\n",
    "print(\"\\n\\n==========================================================\")\n",
    "print(\"TESTING SCENARIO 2: NORMAL SIGNUP\")\n",
    "print(\"==========================================================\")\n",
    "normal_event = \"NEW SIGNUP: I am a 35 year old teacher making $50,000 per year.\"\n",
    "final_state_2 = app.invoke({\"event_data\": normal_event})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb1f30",
   "metadata": {},
   "source": [
    "## (Optional) Azure OpenAI setup (commented example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e230d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you use Azure OpenAI instead, uncomment and configure these:\n",
    "# import os\n",
    "# from openai import AzureOpenAI\n",
    "# AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "# AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  # e.g., https://my-resource.openai.azure.com/\n",
    "# AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-08-01-preview\")\n",
    "# AZURE_OPENAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")  # your deployed model name\n",
    "# client = AzureOpenAI(api_key=AZURE_OPENAI_API_KEY, api_version=AZURE_OPENAI_API_VERSION, azure_endpoint=AZURE_OPENAI_ENDPOINT)\n",
    "# MODEL = AZURE_OPENAI_DEPLOYMENT\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
