{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f38fba0",
   "metadata": {},
   "source": [
    "\n",
    "# Event Agent with LangGraph + OpenAI + LangSmith\n",
    "\n",
    "This notebook integrates:\n",
    "- **LangGraph** for workflow orchestration\n",
    "- **OpenAI** LLM (real API calls, using `OPENAI_API_KEY` from your `.env`)\n",
    "- **LangSmith** tracing (using `LANGSMITH_API_KEY` from your `.env`)\n",
    "\n",
    "## Setup\n",
    "1. Create a `.env` file in the same directory with:\n",
    "```\n",
    "OPENAI_API_KEY=sk-...\n",
    "LANGSMITH_API_KEY=ls-...\n",
    "# Optional overrides:\n",
    "# OPENAI_MODEL=gpt-4o-mini\n",
    "# LANGSMITH_PROJECT=Panel Monitoring Agent\n",
    "```\n",
    "2. Run all cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe6be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langsmith in ./venv/lib/python3.12/site-packages (0.4.30)\n",
      "Requirement already satisfied: langchain-openai in ./venv/lib/python3.12/site-packages (0.3.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith) (3.11.3)\n",
      "Requirement already satisfied: packaging>=23.2 in ./venv/lib/python3.12/site-packages (from langsmith) (25.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./venv/lib/python3.12/site-packages (from langsmith) (2.11.9)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in ./venv/lib/python3.12/site-packages (from langsmith) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1->langsmith) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1->langsmith) (0.4.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.76 in ./venv/lib/python3.12/site-packages (from langchain-openai) (0.3.76)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.104.2 in ./venv/lib/python3.12/site-packages (from langchain-openai) (1.109.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./venv/lib/python3.12/site-packages (from langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.9.18)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith) (2.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "LangSmithConflictError",
     "evalue": "Conflict for https://api.smith.langchain.com/sessions. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/sessions', '{\"detail\":\"Session already exists.\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/panel-monitoring-agent/venv/lib/python3.12/site-packages/langsmith/utils.py:159\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/panel-monitoring-agent/venv/lib/python3.12/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 409 Client Error: Conflict for url: https://api.smith.langchain.com/sessions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/panel-monitoring-agent/venv/lib/python3.12/site-packages/langsmith/client.py:937\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    931\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.session.request(\n\u001b[32m    932\u001b[39m         method,\n\u001b[32m    933\u001b[39m         _construct_url(\u001b[38;5;28mself\u001b[39m.api_url, pathname),\n\u001b[32m    934\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    935\u001b[39m         **request_kwargs,\n\u001b[32m    936\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m937\u001b[39m \u001b[43mls_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/panel-monitoring-agent/venv/lib/python3.12/site-packages/langsmith/utils.py:161\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m requests.HTTPError(\u001b[38;5;28mstr\u001b[39m(e), response.text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mHTTPError\u001b[39m: [Errno 409 Client Error: Conflict for url: https://api.smith.langchain.com/sessions] {\"detail\":\"Session already exists.\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLangSmithConflictError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Ensure project exists *before* tracing\u001b[39;00m\n\u001b[32m     21\u001b[39m c = Client()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPROJECT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEndpoint:\u001b[39m\u001b[33m\"\u001b[39m, c.api_url)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProject:\u001b[39m\u001b[33m\"\u001b[39m, PROJECT)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/panel-monitoring-agent/venv/lib/python3.12/site-packages/langsmith/client.py:3391\u001b[39m, in \u001b[36mClient.create_project\u001b[39m\u001b[34m(self, project_name, description, metadata, upsert, project_extra, reference_dataset_id)\u001b[39m\n\u001b[32m   3389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reference_dataset_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3390\u001b[39m     body[\u001b[33m\"\u001b[39m\u001b[33mreference_dataset_id\u001b[39m\u001b[33m\"\u001b[39m] = reference_dataset_id\n\u001b[32m-> \u001b[39m\u001b[32m3391\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3392\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mContent-Type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_dumps_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3396\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3397\u001b[39m ls_utils.raise_for_status_with_text(response)\n\u001b[32m   3398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ls_schemas.TracerSession(**response.json(), _host_url=\u001b[38;5;28mself\u001b[39m._host_url)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/panel-monitoring-agent/venv/lib/python3.12/site-packages/langsmith/client.py:982\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    977\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithNotFoundError(\n\u001b[32m    978\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResource not found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    979\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    980\u001b[39m     )\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m409\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithConflictError(\n\u001b[32m    983\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConflict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    984\u001b[39m     )\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m403\u001b[39m:\n\u001b[32m    986\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mLangSmithConflictError\u001b[39m: Conflict for https://api.smith.langchain.com/sessions. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/sessions', '{\"detail\":\"Session already exists.\"}')"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, time, uuid\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langsmith import Client\n",
    "from langsmith.run_helpers import trace\n",
    "\n",
    "load_dotenv(find_dotenv(), override=False)\n",
    "\n",
    "# Make sure no sticky session is forcing collisions\n",
    "os.environ.pop(\"LANGSMITH_SESSION\", None)\n",
    "\n",
    "# Tracing + project\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\", \"true\")\n",
    "PROJECT = os.getenv(\"LANGSMITH_PROJECT\") or f\"Panel Monitoring Agent ({datetime.now().strftime('%Y-%m-%d %H:%M')})\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = PROJECT\n",
    "\n",
    "# Ensure project exists *before* tracing\n",
    "c = Client()\n",
    "c.create_project(PROJECT, upsert=True)\n",
    "\n",
    "print(\"Endpoint:\", c.api_url)\n",
    "print(\"Project:\", PROJECT)\n",
    "\n",
    "# Minimal traced ping so the project appears immediately\n",
    "with trace(\n",
    "    name=f\"sanity-ping-{uuid.uuid4().hex[:6]}\",\n",
    "    project_name=PROJECT,\n",
    "    tags=[\"notebook\"]\n",
    "):\n",
    "    pass\n",
    "\n",
    "print(\"✅ Sent traced ping\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c627f2",
   "metadata": {},
   "source": [
    "## Define Graph State and Nodes (with OpenAI + LangSmith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd9ed08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent a traced run. Refresh Studio → Projects.\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import json, random, os\n",
    "from langsmith import traceable\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langsmith.run_helpers import trace\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    event_data: str\n",
    "    signals: dict\n",
    "    action: str\n",
    "    log_entry: str\n",
    "\n",
    "# Structured schema for LLM output\n",
    "class Signals(BaseModel):\n",
    "    suspicious_signup: bool = Field(..., description=\"True if the event is suspicious\")\n",
    "    normal_signup: bool = Field(..., description=\"True if the event is normal\")\n",
    "\n",
    "# LLM client (auto-traced to LangSmith)\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "    temperature=0,\n",
    ")\n",
    "with trace(name=\"sanity-ping\", project_name=os.environ[\"LANGSMITH_PROJECT\"], tags=[\"notebook\"]):\n",
    "    _ = llm.invoke(\"ping\")\n",
    "\n",
    "print(\"Sent a traced run. Refresh Studio → Projects.\")\n",
    "structured = llm.with_structured_output(Signals)\n",
    "\n",
    "@traceable(project_name=os.environ[\"LANGSMITH_PROJECT\"])\n",
    "def user_event_node(state: GraphState) -> GraphState:\n",
    "    print(\"--- 1. User Event Node ---\")\n",
    "    return {\"event_data\": state.get(\"event_data\", \"\"), \"signals\": {}, \"action\": \"\", \"log_entry\": \"\"}\n",
    "\n",
    "def signal_evaluation_node(state: GraphState) -> GraphState:\n",
    "    print(\"--- 2. Signal Evaluation Node: LLM classifying event ---\")\n",
    "    event = state.get(\"event_data\", \"\")\n",
    "    prompt = (\n",
    "        \"Classify the signup event into exactly one of two categories.\\n\"\n",
    "        \"Return booleans for keys 'suspicious_signup' and 'normal_signup' so exactly one is true.\\n\\n\"\n",
    "        f\"Event: {event}\"\n",
    "    )\n",
    "    try:\n",
    "        result: Signals = structured.invoke(prompt)\n",
    "        signals = result.model_dump()\n",
    "        if signals[\"suspicious_signup\"] == signals[\"normal_signup\"]:\n",
    "            heur = \"suspicious\" in event.lower() or (\"director\" in event.lower() and \"22\" in event.lower())\n",
    "            signals = {\"suspicious_signup\": heur, \"normal_signup\": not heur}\n",
    "    except Exception as e:\n",
    "        print(\"LLM error, fallback heuristic:\", e)\n",
    "        heur = \"suspicious\" in event.lower() or (\"director\" in event.lower() and \"22\" in event.lower())\n",
    "        signals = {\"suspicious_signup\": heur, \"normal_signup\": not heur}\n",
    "    return {\"signals\": signals}\n",
    "\n",
    "def action_decision_node(state: GraphState) -> GraphState:\n",
    "    print(\"--- 3. Action Decision Node ---\")\n",
    "    signals = state.get(\"signals\", {})\n",
    "    action = \"no_action\"\n",
    "    if signals.get(\"suspicious_signup\"):\n",
    "        action = \"remove_account\" if random.random() > 0.5 else \"hold_account\"\n",
    "    return {\"action\": action}\n",
    "\n",
    "def logging_node(state: GraphState) -> GraphState:\n",
    "    print(\"--- 4. Logging Node ---\")\n",
    "    log_summary = {\n",
    "        \"event\": state.get(\"event_data\", \"N/A\"),\n",
    "        \"signals_detected\": state.get(\"signals\", {}),\n",
    "        \"final_action\": state.get(\"action\", \"N/A\")\n",
    "    }\n",
    "    log_entry = json.dumps(log_summary, indent=2)\n",
    "    print(\"\\n--- Final Log Entry ---\\n\" + log_entry)\n",
    "    return {\"log_entry\": log_entry}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b34219",
   "metadata": {},
   "source": [
    "## Assemble and Compile the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154c6af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Graph compiled\n"
     ]
    }
   ],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"user_event_node\", user_event_node)\n",
    "workflow.add_node(\"signal_evaluation_node\", signal_evaluation_node)\n",
    "workflow.add_node(\"action_decision_node\", action_decision_node)\n",
    "workflow.add_node(\"logging_node\", logging_node)\n",
    "\n",
    "workflow.add_edge(START, \"user_event_node\")\n",
    "workflow.add_edge(\"user_event_node\", \"signal_evaluation_node\")\n",
    "workflow.add_edge(\"signal_evaluation_node\", \"action_decision_node\")\n",
    "workflow.add_edge(\"action_decision_node\", \"logging_node\")\n",
    "workflow.add_edge(\"logging_node\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "print(\"✅ Graph compiled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251416d4",
   "metadata": {},
   "source": [
    "## Test the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89d238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. User Event Node ---\n",
      "--- 2. Signal Evaluation Node: LLM classifying event ---\n",
      "--- 3. Action Decision Node ---\n",
      "--- 4. Logging Node ---\n",
      "\n",
      "--- Final Log Entry ---\n",
      "{\n",
      "  \"event\": \"NEW SIGNUP: ...\",\n",
      "  \"signals_detected\": {\n",
      "    \"suspicious_signup\": false,\n",
      "    \"normal_signup\": true\n",
      "  },\n",
      "  \"final_action\": \"no_action\"\n",
      "}\n",
      "==========================================================\n",
      "TESTING SCENARIO 1: SUSPICIOUS SIGNUP\n",
      "==========================================================\n",
      "--- 1. User Event Node ---\n",
      "--- 2. Signal Evaluation Node: LLM classifying event ---\n",
      "--- 3. Action Decision Node ---\n",
      "--- 4. Logging Node ---\n",
      "\n",
      "--- Final Log Entry ---\n",
      "{\n",
      "  \"event\": \"NEW SIGNUP: I am a 22 year old Director making $200,000 per year.\",\n",
      "  \"signals_detected\": {\n",
      "    \"suspicious_signup\": true,\n",
      "    \"normal_signup\": false\n",
      "  },\n",
      "  \"final_action\": \"remove_account\"\n",
      "}\n",
      "\n",
      "\n",
      "==========================================================\n",
      "TESTING SCENARIO 2: NORMAL SIGNUP\n",
      "==========================================================\n",
      "--- 1. User Event Node ---\n",
      "--- 2. Signal Evaluation Node: LLM classifying event ---\n",
      "--- 3. Action Decision Node ---\n",
      "--- 4. Logging Node ---\n",
      "\n",
      "--- Final Log Entry ---\n",
      "{\n",
      "  \"event\": \"NEW SIGNUP: I am a 35 year old teacher making $50,000 per year.\",\n",
      "  \"signals_detected\": {\n",
      "    \"suspicious_signup\": false,\n",
      "    \"normal_signup\": true\n",
      "  },\n",
      "  \"final_action\": \"no_action\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langsmith.run_helpers import trace\n",
    "\n",
    "with trace(name=\"Event Agent Run\", project_name=os.environ[\"LANGSMITH_PROJECT\"]):\n",
    "    final_state = app.invoke({\"event_data\": \"NEW SIGNUP: ...\"}) \n",
    "    print(\"==========================================================\")\n",
    "    print(\"TESTING SCENARIO 1: SUSPICIOUS SIGNUP\")\n",
    "    print(\"==========================================================\")\n",
    "    suspicious_event = \"NEW SIGNUP: I am a 22 year old Director making $200,000 per year.\"\n",
    "    final_state_1 = app.invoke({\"event_data\": suspicious_event})\n",
    "\n",
    "    print(\"\\n\\n==========================================================\")\n",
    "    print(\"TESTING SCENARIO 2: NORMAL SIGNUP\")\n",
    "    print(\"==========================================================\")\n",
    "    normal_event = \"NEW SIGNUP: I am a 35 year old teacher making $50,000 per year.\"\n",
    "    final_state_2 = app.invoke({\"event_data\": normal_event})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b5223-2ed5-4f73-9ae3-9ede6cd05ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
