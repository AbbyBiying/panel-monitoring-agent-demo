{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f38fba0",
   "metadata": {},
   "source": [
    "\n",
    "# Event Agent with LangGraph + OpenAI + LangSmith\n",
    "\n",
    "This notebook integrates:\n",
    "- **LangGraph** for workflow orchestration\n",
    "- **OpenAI** LLM (real API calls, using `OPENAI_API_KEY` from your `.env`)\n",
    "- **LangSmith** tracing (using `LANGSMITH_API_KEY` from your `.env`)\n",
    "\n",
    "## Setup\n",
    "1. Create a `.env` file in the same directory with:\n",
    "```\n",
    "OPENAI_API_KEY=sk-...\n",
    "LANGSMITH_API_KEY=ls-...\n",
    "# Optional overrides:\n",
    "# OPENAI_MODEL=gpt-4o-mini\n",
    "# LANGSMITH_PROJECT=Panel Monitoring Agent\n",
    "```\n",
    "2. Run all cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install deps inside the notebook kernel if needed\n",
    "%pip install -U python-dotenv langchain-openai langsmith langgraph\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# Load env vars\n",
    "load_dotenv(find_dotenv(), override=False)\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY missing in .env\"\n",
    "assert os.getenv(\"LANGSMITH_API_KEY\"), \"LANGSMITH_API_KEY missing in .env\"\n",
    "\n",
    "# Enable LangSmith tracing\n",
    "os.environ.setdefault(\"LANGSMITH_TRACING\", \"true\")\n",
    "os.environ.setdefault(\"LANGSMITH_PROJECT\", os.getenv(\"LANGSMITH_PROJECT\", \"Panel Monitoring Agent\"))\n",
    "\n",
    "print(\"✅ Environment loaded\")\n",
    "print(\"Tracing:\", os.getenv(\"LANGSMITH_TRACING\"))\n",
    "print(\"Project:\", os.getenv(\"LANGSMITH_PROJECT\"))\n",
    "print(\"Model:\", os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c627f2",
   "metadata": {},
   "source": [
    "## Define Graph State and Nodes (with OpenAI + LangSmith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd9ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import json, random, os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    event_data: str\n",
    "    signals: dict\n",
    "    action: str\n",
    "    log_entry: str\n",
    "\n",
    "# Structured schema for LLM output\n",
    "class Signals(BaseModel):\n",
    "    suspicious_signup: bool = Field(..., description=\"True if the event is suspicious\")\n",
    "    normal_signup: bool = Field(..., description=\"True if the event is normal\")\n",
    "\n",
    "# LLM client (auto-traced to LangSmith)\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "structured = llm.with_structured_output(Signals)\n",
    "\n",
    "def user_event_node(state: GraphState) -> GraphState:\n",
    "    print(\"--- 1. User Event Node ---\")\n",
    "    return {\"event_data\": state.get(\"event_data\", \"\"), \"signals\": {}, \"action\": \"\", \"log_entry\": \"\"}\n",
    "\n",
    "def signal_evaluation_node(state: GraphState) -> GraphState:\n",
    "    print(\"--- 2. Signal Evaluation Node: LLM classifying event ---\")\n",
    "    event = state.get(\"event_data\", \"\")\n",
    "    prompt = (\n",
    "        \"Classify the signup event into exactly one of two categories.\\n\"\n",
    "        \"Return booleans for keys 'suspicious_signup' and 'normal_signup' so exactly one is true.\\n\\n\"\n",
    "        f\"Event: {event}\"\n",
    "    )\n",
    "    try:\n",
    "        result: Signals = structured.invoke(prompt)\n",
    "        signals = result.model_dump()\n",
    "        if signals[\"suspicious_signup\"] == signals[\"normal_signup\"]:\n",
    "            heur = \"suspicious\" in event.lower() or (\"director\" in event.lower() and \"22\" in event.lower())\n",
    "            signals = {\"suspicious_signup\": heur, \"normal_signup\": not heur}\n",
    "    except Exception as e:\n",
    "        print(\"LLM error, fallback heuristic:\", e)\n",
    "        heur = \"suspicious\" in event.lower() or (\"director\" in event.lower() and \"22\" in event.lower())\n",
    "        signals = {\"suspicious_signup\": heur, \"normal_signup\": not heur}\n",
    "    return {\"signals\": signals}\n",
    "\n",
    "def action_decision_node(state: GraphState) -> GraphState:\n",
    "    print(\"--- 3. Action Decision Node ---\")\n",
    "    signals = state.get(\"signals\", {})\n",
    "    action = \"no_action\"\n",
    "    if signals.get(\"suspicious_signup\"):\n",
    "        action = \"remove_account\" if random.random() > 0.5 else \"hold_account\"\n",
    "    return {\"action\": action}\n",
    "\n",
    "def logging_node(state: GraphState) -> GraphState:\n",
    "    print(\"--- 4. Logging Node ---\")\n",
    "    log_summary = {\n",
    "        \"event\": state.get(\"event_data\", \"N/A\"),\n",
    "        \"signals_detected\": state.get(\"signals\", {}),\n",
    "        \"final_action\": state.get(\"action\", \"N/A\")\n",
    "    }\n",
    "    log_entry = json.dumps(log_summary, indent=2)\n",
    "    print(\"\\n--- Final Log Entry ---\\n\" + log_entry)\n",
    "    return {\"log_entry\": log_entry}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b34219",
   "metadata": {},
   "source": [
    "## Assemble and Compile the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"user_event_node\", user_event_node)\n",
    "workflow.add_node(\"signal_evaluation_node\", signal_evaluation_node)\n",
    "workflow.add_node(\"action_decision_node\", action_decision_node)\n",
    "workflow.add_node(\"logging_node\", logging_node)\n",
    "\n",
    "workflow.add_edge(START, \"user_event_node\")\n",
    "workflow.add_edge(\"user_event_node\", \"signal_evaluation_node\")\n",
    "workflow.add_edge(\"signal_evaluation_node\", \"action_decision_node\")\n",
    "workflow.add_edge(\"action_decision_node\", \"logging_node\")\n",
    "workflow.add_edge(\"logging_node\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "print(\"✅ Graph compiled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251416d4",
   "metadata": {},
   "source": [
    "## Test the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==========================================================\")\n",
    "print(\"TESTING SCENARIO 1: SUSPICIOUS SIGNUP\")\n",
    "print(\"==========================================================\")\n",
    "suspicious_event = \"NEW SIGNUP: I am a 22 year old Director making $200,000 per year.\"\n",
    "final_state_1 = app.invoke({\"event_data\": suspicious_event})\n",
    "\n",
    "print(\"\\n\\n==========================================================\")\n",
    "print(\"TESTING SCENARIO 2: NORMAL SIGNUP\")\n",
    "print(\"==========================================================\")\n",
    "normal_event = \"NEW SIGNUP: I am a 35 year old teacher making $50,000 per year.\"\n",
    "final_state_2 = app.invoke({\"event_data\": normal_event})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
